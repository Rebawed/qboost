1----------------------------------
Number of features: 67500
Number of training samples: 320
Number of test samples: 80
Performing cross-validation using 5 values of lambda, this make take several minutes...
lambda  n_features score:
0.0009  54         0.609 
0.0012  48         0.625 
0.0016  43         0.617 
0.0019  37         0.586 
0.0022  31         0.602 
Accuracy of weak classifiers (score on test set):
  count    min    mean    max    std
-------  -----  ------  -----  -----
    150  0.463   0.637  0.750  0.043
Number of selected features: 48
Score on test set: 0.662
The predicted Data is :
[ 1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.
  1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.  1. -1. -1.
  1. -1. -1.  1. -1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.
 -1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1.
  1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1. -1.  1. -1. -1.
 -1.  1. -1.  1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1.
  1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1.
 -1. -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1. -1.
  1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.
  1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1.  1. -1.
 -1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.
  1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1. -1.
 -1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1.
 -1.  1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1.
 -1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.  1.
 -1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.
  1. -1. -1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1. -1.  1.
 -1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1.]
The actual data is:
[ 1 -1 -1 -1  1 -1 -1  1  1  1  1  1 -1 -1 -1 -1 -1  1  1  1  1 -1  1 -1
  1  1 -1  1 -1  1 -1 -1  1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1  1
  1 -1 -1  1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1 -1  1 -1 -1 -1  1 -1
  1 -1 -1 -1  1 -1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1  1
 -1 -1  1  1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1  1 -1
 -1 -1 -1  1  1  1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1
  1 -1 -1  1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1
 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1  1  1
  1 -1  1 -1  1 -1  1 -1  1 -1  1 -1 -1  1 -1 -1  1  1  1 -1 -1 -1  1 -1
 -1 -1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1 -1
 -1  1  1  1  1 -1 -1 -1  1  1 -1 -1  1 -1  1 -1  1  1  1 -1 -1  1  1  1
 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1 -1  1  1 -1 -1  1
  1 -1 -1 -1  1 -1  1 -1 -1  1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1 -1
  1 -1  1  1 -1 -1 -1 -1]
Precision score 0.6709677419354839
Recall score 0.8524590163934426
F1-score score 0.7509025270758123
Accuracy score 0.784375

2---------------------------

loading... category : Maggiorenne
loaded category:Maggiorenne successfully
loading... category : Minorenne
loaded category:Minorenne successfully
Number of features: 67500
Number of training samples: 320
Number of test samples: 80
Performing cross-validation using 5 values of lambda, this make take several minutes...
lambda  n_features score:
0.0018  41         0.570 
0.0024  30         0.578 
0.0031  19         0.586 
0.0038  7          0.562 
0.0044  1          0.656 
Accuracy of weak classifiers (score on test set):
  count    min    mean    max    std
-------  -----  ------  -----  -----
    150  0.450   0.637  0.700  0.037
Number of selected features: 1
Score on test set: 0.500
The predicted Data is :
[-1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.  1.  1.
  1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1.
  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.
  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.
  1. -1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1.
 -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.
  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.
 -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1. -1.
  1. -1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1.
  1.  1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.
  1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.
  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1.
  1.  1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1.
 -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1. -1.  1.
  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1.
  1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1.
  1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1.  1.
  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1. -1.]
The actual data is:
[ 1 -1 -1 -1  1 -1 -1  1  1  1  1  1 -1 -1 -1 -1 -1  1  1  1  1 -1  1 -1
  1  1 -1  1 -1  1 -1 -1  1 -1  1 -1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1  1
  1 -1 -1  1 -1 -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1 -1  1 -1 -1 -1  1 -1
  1 -1 -1 -1  1 -1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1  1
 -1 -1  1  1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1  1  1 -1 -1 -1 -1 -1  1 -1
 -1 -1 -1  1  1  1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1
  1 -1 -1  1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1
 -1 -1 -1  1 -1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1  1  1
  1 -1  1 -1  1 -1  1 -1  1 -1  1 -1 -1  1 -1 -1  1  1  1 -1 -1 -1  1 -1
 -1 -1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1 -1
 -1  1  1  1  1 -1 -1 -1  1  1 -1 -1  1 -1  1 -1  1  1  1 -1 -1  1  1  1
 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1 -1  1  1 -1 -1  1
  1 -1 -1 -1  1 -1  1 -1 -1  1  1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1 -1 -1
  1 -1  1  1 -1 -1 -1 -1]
Precision score 0.5743589743589743
Recall score 0.9180327868852459
F1-score score 0.7066246056782335
Accuracy score 0.709375

3---------------------randomstate=0

Number of features: 67500
Number of training samples: 320
Number of test samples: 80
Performing cross-validation using 10 values of lambda, this make take several minutes...
lambda  n_features score:
0.0009  52         0.680 
0.0010  50         0.688 
0.0012  48         0.680 
0.0013  47         0.680 
0.0015  45         0.695 
0.0016  43         0.695 
0.0018  42         0.688 
0.0019  40         0.680 
0.0021  39         0.680 
0.0022  37         0.680 
Accuracy of weak classifiers (score on test set):
  count    min    mean    max    std
-------  -----  ------  -----  -----
    150  0.550   0.648  0.700  0.021
Number of selected features: 45
Score on test set: 0.613
The predicted Data is :
[-1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1.
 -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.
 -1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1.
 -1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1.  1.
  1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.
 -1. -1.  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1.  1.
 -1.  1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1.
 -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.  1. -1.
 -1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.  1.
 -1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1.
 -1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1.
  1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1.
 -1. -1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.
  1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.
 -1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1.
 -1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.
 -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.
 -1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1.]
The actual data is:
[-1 -1 -1  1  1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1 -1 -1
 -1 -1 -1 -1  1  1 -1  1  1  1  1 -1 -1  1  1  1 -1 -1 -1  1 -1 -1  1  1
 -1 -1  1 -1  1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1  1 -1  1
  1 -1 -1 -1 -1 -1  1  1  1 -1  1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1
 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1 -1  1 -1  1  1  1  1  1  1
 -1 -1  1 -1  1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1  1  1  1  1  1 -1  1 -1
 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1  1  1  1 -1 -1  1 -1 -1  1 -1
 -1  1 -1 -1 -1  1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1
  1  1 -1 -1  1 -1  1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1
 -1  1 -1  1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1  1 -1  1  1 -1 -1
 -1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1  1 -1
  1 -1  1  1 -1 -1  1 -1  1 -1  1  1 -1  1  1  1 -1 -1 -1 -1 -1  1 -1 -1
 -1 -1  1 -1  1 -1  1 -1  1 -1  1  1  1  1 -1 -1 -1  1 -1  1 -1  1 -1 -1
  1 -1 -1 -1 -1  1  1 -1]
Precision score 0.6447368421052632
Recall score 0.8032786885245902
F1-score score 0.7153284671532848
Accuracy score 0.75625

4-------------randomstate=0

Number of features: 67500
Number of training samples: 320
Number of test samples: 80
Performing cross-validation using 10 values of lambda, this make take several minutes...
lambda  n_features score:
0.0009  53         0.586 
0.0010  51         0.570 
0.0012  49         0.578 
0.0013  47         0.594 
0.0015  44         0.633 
0.0016  41         0.641 
0.0018  40         0.625 
0.0019  37         0.648 
0.0021  36         0.625 
0.0022  34         0.625 
Accuracy of weak classifiers (score on test set):
  count    min    mean    max    std
-------  -----  ------  -----  -----
    150  0.487   0.622  0.750  0.031
Number of selected features: 37
Score on test set: 0.725
The predicted Data is :
[ 1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1.  1.
 -1. -1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1.
 -1.  1.  1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1.
 -1. -1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.
  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.
 -1.  1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1.
 -1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1.  1.  1.
 -1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1.  1.
 -1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1.
  1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1.
  1. -1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1.
 -1. -1.  1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.
 -1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.
 -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.
 -1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1.  1. -1.
 -1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.
 -1.  1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1.
 -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1.]
The actual data is:
[ 1 -1 -1 -1 -1  1 -1  1 -1  1 -1  1  1  1 -1  1 -1  1 -1 -1  1 -1 -1  1
 -1  1 -1 -1  1  1  1 -1 -1 -1 -1  1 -1  1 -1 -1 -1  1 -1 -1  1 -1 -1  1
 -1 -1  1 -1 -1 -1 -1 -1  1 -1  1 -1  1 -1 -1 -1  1  1 -1 -1  1 -1 -1  1
 -1 -1  1  1 -1  1 -1  1 -1 -1  1 -1  1  1 -1 -1 -1  1 -1  1 -1 -1  1 -1
 -1 -1  1  1 -1  1 -1  1 -1 -1 -1 -1 -1  1 -1 -1  1  1 -1 -1 -1 -1 -1  1
  1  1 -1 -1 -1 -1  1 -1  1 -1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1  1 -1  1
 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1 -1  1  1  1 -1 -1 -1  1  1 -1  1  1 -1
 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1  1 -1  1  1 -1 -1 -1  1  1 -1
  1  1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1
 -1 -1  1  1 -1 -1  1 -1  1 -1 -1 -1 -1 -1  1  1  1  1 -1  1  1 -1 -1 -1
  1 -1 -1  1 -1 -1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1  1 -1 -1 -1  1 -1 -1
 -1  1 -1  1  1 -1 -1  1 -1  1 -1  1 -1  1  1  1 -1  1 -1  1 -1 -1  1  1
 -1  1 -1 -1 -1  1  1 -1 -1  1 -1  1  1 -1 -1  1 -1 -1 -1 -1  1  1 -1 -1
 -1  1 -1 -1 -1 -1 -1 -1]
Precision score 0.725
Recall score 0.725
F1-score score 0.7250000000000001
Accuracy score 0.79375

5------------randomstate=0
Number of features: 67500
Number of training samples: 480
Number of test samples: 120
Performing cross-validation using 5 values of lambda, this make take several minutes...
lambda  n_features score:
0.0009  42         0.667 
0.0012  37         0.682 
0.0016  31         0.698 
0.0019  25         0.677 
0.0022  18         0.688 
Accuracy of weak classifiers (score on test set):
  count    min    mean    max    std
-------  -----  ------  -----  -----
    150  0.442   0.498  0.658  0.036
Number of selected features: 31
Score on test set: 0.683
The predicted Data is :
[ 1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.
  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1.  1.
  1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1. -1.
  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1.
 -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1.
 -1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1. -1.
 -1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.
 -1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.
 -1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.
 -1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1.
  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1.  1.
 -1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.
  1.  1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.
  1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.
 -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1. -1.  1.  1. -1.
 -1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1. -1.
 -1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.
 -1. -1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1. -1. -1.  1.
 -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1.
 -1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1. -1.  1.
  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1.
 -1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1.
 -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.  1. -1. -1.
  1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1.  1. -1. -1.  1.
  1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1. -1.
 -1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1.
 -1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1.  1.]
The actual data is:
[-1  1 -1 -1  1  1  1  1  1  1 -1 -1  1  1 -1  1 -1 -1 -1  1 -1  1 -1 -1
  1  1 -1  1  1 -1 -1 -1  1 -1 -1  1  1 -1 -1 -1 -1 -1  1 -1  1  1  1  1
  1  1 -1  1 -1 -1  1 -1  1  1  1 -1  1  1  1 -1  1  1 -1  1 -1 -1  1 -1
 -1 -1 -1 -1 -1  1  1  1 -1  1  1  1 -1  1  1  1  1  1 -1 -1 -1 -1  1 -1
 -1  1 -1  1  1  1  1  1  1  1  1  1 -1  1 -1  1 -1  1  1  1  1  1 -1  1
 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1  1  1  1 -1 -1  1 -1 -1 -1  1 -1
 -1 -1  1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1  1  1 -1 -1 -1  1  1  1  1 -1
 -1  1 -1  1  1 -1 -1 -1  1  1 -1 -1  1 -1 -1  1  1  1  1 -1  1 -1  1  1
  1 -1 -1 -1  1  1 -1 -1  1 -1 -1  1  1  1  1 -1  1  1  1  1 -1 -1 -1 -1
  1  1  1 -1  1 -1 -1  1 -1  1 -1 -1 -1  1  1 -1  1  1  1 -1  1 -1  1  1
  1  1  1 -1  1 -1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1  1  1  1
  1  1 -1  1  1 -1 -1 -1 -1  1 -1  1  1  1  1  1 -1 -1  1  1 -1  1  1 -1
 -1 -1  1  1  1 -1  1 -1 -1  1 -1 -1 -1 -1 -1  1 -1  1  1 -1 -1  1 -1 -1
 -1 -1 -1 -1  1 -1  1  1  1 -1 -1  1 -1 -1 -1  1  1 -1 -1  1 -1  1  1  1
 -1 -1 -1  1 -1 -1  1  1 -1  1  1  1 -1 -1  1 -1  1 -1  1  1  1 -1  1  1
  1  1 -1  1 -1  1 -1  1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1  1  1  1 -1 -1
  1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1  1  1  1
  1 -1  1  1 -1 -1 -1 -1  1 -1  1  1 -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1  1
 -1 -1 -1  1 -1  1  1 -1  1  1 -1  1  1 -1  1 -1 -1 -1  1  1 -1 -1  1  1
 -1 -1  1 -1 -1 -1  1  1 -1 -1  1 -1 -1  1  1  1  1  1 -1 -1 -1  1 -1  1]
Precision score 0.7824267782426778
Recall score 0.7923728813559322
F1-score score 0.7873684210526315
Accuracy score 0.7895833333333333